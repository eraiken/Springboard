{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95840d89",
   "metadata": {},
   "source": [
    "# Capstone 3 - Exploratory Data Analysis\n",
    "\n",
    "### Table of contents\n",
    "* [Introduction](#intro)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2273250",
   "metadata": {},
   "source": [
    "## Introduction <a name=\"intro\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27235176",
   "metadata": {},
   "source": [
    "### Import relevant packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f727784",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2764291",
   "metadata": {},
   "source": [
    "### Retrieve variables\n",
    "Let's retrieve the variables we saved in our data cleaning & wrangling phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c9eb3672",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve original noise_data dataframe\n",
    "%store -r noise_data\n",
    "\n",
    "# Retrieve GeoPandas dataframes\n",
    "%store -r districts_gdf \n",
    "%store -r schoolpoints_gdf\n",
    "\n",
    "# Retrieve schools covered by sensor range\n",
    "%store -r coverage_matrix\n",
    "\n",
    "# Retrieve summary and achievement dataframes\n",
    "%store -r summary_dfs\n",
    "%store -r lg_achievement_dfs\n",
    "%store -r hs_achievement_dfs\n",
    "%store -r combined_summary_df\n",
    "%store -r combined_achievement_df\n",
    "%store -r merged_coverage_df\n",
    "\n",
    "# Retrieve school lists\n",
    "%store -r elem_middle_schools\n",
    "%store -r high_schools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4889d30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = merged_coverage_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ce27142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================== Final Merged Dataset Analysis ====================\n",
      "\n",
      "1. Basic Information:\n",
      "Number of rows: 207\n",
      "Number of columns: 102\n",
      "Memory usage: 0.16 MB\n",
      "\n",
      "2. Missing Values Analysis:\n",
      "\n",
      "Columns with missing values:\n",
      "                               Missing Values  Percentage\n",
      "regents_global                            135   65.217391\n",
      "regents_living_env                        129   62.318841\n",
      "regents_us_history                        129   62.318841\n",
      "regents_algebra                           126   60.869565\n",
      "college_ready_6yr                         121   58.454106\n",
      "grad_rate_6yr                             121   58.454106\n",
      "postsec_enroll_18mo                       121   58.454106\n",
      "postsec_enroll_6mo                        115   55.555556\n",
      "math_proficient_pct                       114   55.072464\n",
      "math_lowest_third_proficiency             114   55.072464\n",
      "math_avg_proficiency                      114   55.072464\n",
      "ela_avg_proficiency                       112   54.106280\n",
      "ela_lowest_third_proficiency              112   54.106280\n",
      "ela_proficient_pct                        112   54.106280\n",
      "college_ready_4yr                         110   53.140097\n",
      "college_prep_index                        110   53.140097\n",
      "grad_rate_4yr                             110   53.140097\n",
      "grad_rate_n                               109   52.657005\n",
      "college_ready_n                           109   52.657005\n",
      "math_lowest_third_n                       105   50.724638\n",
      "ela_lowest_third_n                        105   50.724638\n",
      "math_proficient_n                         105   50.724638\n",
      "ela_proficient_n                          105   50.724638\n",
      "credits_yr3                               104   50.241546\n",
      "regents_english                           102   49.275362\n",
      "credits_yr1                               102   49.275362\n",
      "credits_yr2                               102   49.275362\n",
      "regents_english_n                         102   49.275362\n",
      "achievement_score                          18    8.695652\n",
      "achievement_rating                         18    8.695652\n",
      "teacher_attendance_rate                     9    4.347826\n",
      "chronic_absence_pct                         5    2.415459\n",
      "attendance_90_plus_pct                      5    2.415459\n",
      "student_attendance_rate                     5    2.415459\n",
      "\n",
      "3. Data Types:\n",
      "int64      54\n",
      "object     46\n",
      "float64     2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Detailed dtypes:\n",
      "DBN               object\n",
      "school_name       object\n",
      "enrollment        object\n",
      "ell_pct           object\n",
      "disability_pct    object\n",
      "                   ...  \n",
      "sensor_6           int64\n",
      "sensor_61          int64\n",
      "sensor_7           int64\n",
      "sensor_8           int64\n",
      "sensor_9           int64\n",
      "Length: 102, dtype: object\n",
      "\n",
      "4. Numerical Columns Summary:\n",
      "       num_sensors  num_recordings  min_distance_km  max_distance_km  \\\n",
      "count   207.000000      207.000000       207.000000       207.000000   \n",
      "mean      2.739130      804.420290         1.234836         1.556242   \n",
      "std       1.935756     1091.228755         0.561234         0.442187   \n",
      "min       1.000000        3.000000         0.339470         0.453611   \n",
      "25%       1.000000       72.000000         0.785748         1.332921   \n",
      "50%       2.000000      584.000000         1.310983         1.773424   \n",
      "75%       4.000000     1093.000000         1.755361         1.927432   \n",
      "max      10.000000     5264.000000         1.997274         1.997274   \n",
      "\n",
      "       sensor_0    sensor_1   sensor_10   sensor_11  sensor_12   sensor_13  \\\n",
      "count     207.0  207.000000  207.000000  207.000000      207.0  207.000000   \n",
      "mean        0.0    0.028986    0.014493    0.086957        0.0    0.159420   \n",
      "std         0.0    0.168172    0.119800    0.282454        0.0    0.366955   \n",
      "min         0.0    0.000000    0.000000    0.000000        0.0    0.000000   \n",
      "25%         0.0    0.000000    0.000000    0.000000        0.0    0.000000   \n",
      "50%         0.0    0.000000    0.000000    0.000000        0.0    0.000000   \n",
      "75%         0.0    0.000000    0.000000    0.000000        0.0    0.000000   \n",
      "max         0.0    1.000000    1.000000    1.000000        0.0    1.000000   \n",
      "\n",
      "       ...   sensor_52   sensor_53   sensor_55   sensor_56   sensor_57  \\\n",
      "count  ...  207.000000  207.000000  207.000000  207.000000  207.000000   \n",
      "mean   ...    0.014493    0.014493    0.014493    0.043478    0.115942   \n",
      "std    ...    0.119800    0.119800    0.119800    0.204425    0.320932   \n",
      "min    ...    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "25%    ...    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "50%    ...    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "75%    ...    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "max    ...    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
      "\n",
      "         sensor_6   sensor_61  sensor_7    sensor_8  sensor_9  \n",
      "count  207.000000  207.000000     207.0  207.000000     207.0  \n",
      "mean     0.231884    0.014493       0.0    0.231884       0.0  \n",
      "std      0.423058    0.119800       0.0    0.423058       0.0  \n",
      "min      0.000000    0.000000       0.0    0.000000       0.0  \n",
      "25%      0.000000    0.000000       0.0    0.000000       0.0  \n",
      "50%      0.000000    0.000000       0.0    0.000000       0.0  \n",
      "75%      0.000000    0.000000       0.0    0.000000       0.0  \n",
      "max      1.000000    1.000000       0.0    1.000000       0.0  \n",
      "\n",
      "[8 rows x 56 columns]\n",
      "\n",
      "5. Potential Outliers (values > 3 std devs from mean):\n",
      "\n",
      "num_sensors:\n",
      "Number of outliers: 6\n",
      "Outlier values: num_sensors\n",
      "9     3\n",
      "10    3\n",
      "Name: count, dtype: int64\n",
      "\n",
      "num_recordings:\n",
      "Number of outliers: 9\n",
      "Outlier values: num_recordings\n",
      "4864    3\n",
      "4474    3\n",
      "5264    3\n",
      "Name: count, dtype: int64\n",
      "\n",
      "sensor_1:\n",
      "Number of outliers: 6\n",
      "Outlier values: sensor_1\n",
      "1    6\n",
      "Name: count, dtype: int64\n",
      "\n",
      "sensor_10:\n",
      "Number of outliers: 3\n",
      "Outlier values: sensor_10\n",
      "1    3\n",
      "Name: count, dtype: int64\n",
      "\n",
      "sensor_11:\n",
      "Number of outliers: 18\n",
      "Outlier values: sensor_11\n",
      "1    18\n",
      "Name: count, dtype: int64\n",
      "\n",
      "sensor_17:\n",
      "Number of outliers: 3\n",
      "Outlier values: sensor_17\n",
      "1    3\n",
      "Name: count, dtype: int64\n",
      "\n",
      "sensor_19:\n",
      "Number of outliers: 18\n",
      "Outlier values: sensor_19\n",
      "1    18\n",
      "Name: count, dtype: int64\n",
      "\n",
      "sensor_2:\n",
      "Number of outliers: 3\n",
      "Outlier values: sensor_2\n",
      "1    3\n",
      "Name: count, dtype: int64\n",
      "\n",
      "sensor_20:\n",
      "Number of outliers: 3\n",
      "Outlier values: sensor_20\n",
      "1    3\n",
      "Name: count, dtype: int64\n",
      "\n",
      "sensor_23:\n",
      "Number of outliers: 3\n",
      "Outlier values: sensor_23\n",
      "1    3\n",
      "Name: count, dtype: int64\n",
      "\n",
      "sensor_24:\n",
      "Number of outliers: 9\n",
      "Outlier values: sensor_24\n",
      "1    9\n",
      "Name: count, dtype: int64\n",
      "\n",
      "sensor_26:\n",
      "Number of outliers: 6\n",
      "Outlier values: sensor_26\n",
      "1    6\n",
      "Name: count, dtype: int64\n",
      "\n",
      "sensor_29:\n",
      "Number of outliers: 6\n",
      "Outlier values: sensor_29\n",
      "1    6\n",
      "Name: count, dtype: int64\n",
      "\n",
      "sensor_30:\n",
      "Number of outliers: 6\n",
      "Outlier values: sensor_30\n",
      "1    6\n",
      "Name: count, dtype: int64\n",
      "\n",
      "sensor_31:\n",
      "Number of outliers: 3\n",
      "Outlier values: sensor_31\n",
      "1    3\n",
      "Name: count, dtype: int64\n",
      "\n",
      "sensor_32:\n",
      "Number of outliers: 9\n",
      "Outlier values: sensor_32\n",
      "1    9\n",
      "Name: count, dtype: int64\n",
      "\n",
      "sensor_33:\n",
      "Number of outliers: 3\n",
      "Outlier values: sensor_33\n",
      "1    3\n",
      "Name: count, dtype: int64\n",
      "\n",
      "sensor_34:\n",
      "Number of outliers: 6\n",
      "Outlier values: sensor_34\n",
      "1    6\n",
      "Name: count, dtype: int64\n",
      "\n",
      "sensor_35:\n",
      "Number of outliers: 3\n",
      "Outlier values: sensor_35\n",
      "1    3\n",
      "Name: count, dtype: int64\n",
      "\n",
      "sensor_38:\n",
      "Number of outliers: 9\n",
      "Outlier values: sensor_38\n",
      "1    9\n",
      "Name: count, dtype: int64\n",
      "\n",
      "sensor_39:\n",
      "Number of outliers: 3\n",
      "Outlier values: sensor_39\n",
      "1    3\n",
      "Name: count, dtype: int64\n",
      "\n",
      "sensor_4:\n",
      "Number of outliers: 3\n",
      "Outlier values: sensor_4\n",
      "1    3\n",
      "Name: count, dtype: int64\n",
      "\n",
      "sensor_41:\n",
      "Number of outliers: 9\n",
      "Outlier values: sensor_41\n",
      "1    9\n",
      "Name: count, dtype: int64\n",
      "\n",
      "sensor_45:\n",
      "Number of outliers: 9\n",
      "Outlier values: sensor_45\n",
      "1    9\n",
      "Name: count, dtype: int64\n",
      "\n",
      "sensor_48:\n",
      "Number of outliers: 6\n",
      "Outlier values: sensor_48\n",
      "1    6\n",
      "Name: count, dtype: int64\n",
      "\n",
      "sensor_49:\n",
      "Number of outliers: 15\n",
      "Outlier values: sensor_49\n",
      "1    15\n",
      "Name: count, dtype: int64\n",
      "\n",
      "sensor_51:\n",
      "Number of outliers: 15\n",
      "Outlier values: sensor_51\n",
      "1    15\n",
      "Name: count, dtype: int64\n",
      "\n",
      "sensor_52:\n",
      "Number of outliers: 3\n",
      "Outlier values: sensor_52\n",
      "1    3\n",
      "Name: count, dtype: int64\n",
      "\n",
      "sensor_53:\n",
      "Number of outliers: 3\n",
      "Outlier values: sensor_53\n",
      "1    3\n",
      "Name: count, dtype: int64\n",
      "\n",
      "sensor_55:\n",
      "Number of outliers: 3\n",
      "Outlier values: sensor_55\n",
      "1    3\n",
      "Name: count, dtype: int64\n",
      "\n",
      "sensor_56:\n",
      "Number of outliers: 9\n",
      "Outlier values: sensor_56\n",
      "1    9\n",
      "Name: count, dtype: int64\n",
      "\n",
      "sensor_61:\n",
      "Number of outliers: 3\n",
      "Outlier values: sensor_61\n",
      "1    3\n",
      "Name: count, dtype: int64\n",
      "\n",
      "6. Categorical Columns Summary:\n",
      "\n",
      "DBN:\n",
      "Number of unique values: 54\n",
      "\n",
      "school_name:\n",
      "Number of unique values: 54\n",
      "\n",
      "enrollment:\n",
      "Number of unique values: 107\n",
      "\n",
      "ell_pct:\n",
      "Number of unique values: 80\n",
      "\n",
      "disability_pct:\n",
      "Number of unique values: 95\n",
      "\n",
      "self_contained_pct:\n",
      "Number of unique values: 41\n",
      "\n",
      "asian_pct:\n",
      "Number of unique values: 98\n",
      "\n",
      "black_pct:\n",
      "Number of unique values: 107\n",
      "\n",
      "hispanic_pct:\n",
      "Number of unique values: 111\n",
      "\n",
      "white_pct:\n",
      "Number of unique values: 95\n",
      "\n",
      "student_attendance_rate:\n",
      "Number of unique values: 84\n",
      "\n",
      "chronic_absence_pct:\n",
      "Number of unique values: 107\n",
      "\n",
      "teacher_attendance_rate:\n",
      "Number of unique values: 35\n",
      "\n",
      "academic_year:\n",
      "Number of unique values: 3\n",
      "academic_year\n",
      "2016-2017    69\n",
      "2017-2018    69\n",
      "2018-2019    69\n",
      "Name: count, dtype: int64\n",
      "\n",
      "school_type:\n",
      "Number of unique values: 4\n",
      "school_type\n",
      "High School    105\n",
      "Elementary      54\n",
      "Middle          39\n",
      "K-8              9\n",
      "Name: count, dtype: int64\n",
      "\n",
      "achievement_rating:\n",
      "Number of unique values: 4\n",
      "achievement_rating\n",
      "Meeting Target        78\n",
      "Approaching Target    57\n",
      "Exceeding Target      52\n",
      "Not Meeting Target     2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "achievement_score:\n",
      "Number of unique values: 91\n",
      "\n",
      "ela_proficient_pct:\n",
      "Number of unique values: 54\n",
      "\n",
      "ela_avg_proficiency:\n",
      "Number of unique values: 47\n",
      "\n",
      "ela_lowest_third_proficiency:\n",
      "Number of unique values: 49\n",
      "\n",
      "math_proficient_pct:\n",
      "Number of unique values: 54\n",
      "\n",
      "math_avg_proficiency:\n",
      "Number of unique values: 45\n",
      "\n",
      "math_lowest_third_proficiency:\n",
      "Number of unique values: 48\n",
      "\n",
      "attendance_90_plus_pct:\n",
      "Number of unique values: 107\n",
      "\n",
      "ela_proficient_n:\n",
      "Number of unique values: 52\n",
      "\n",
      "math_proficient_n:\n",
      "Number of unique values: 53\n",
      "\n",
      "ela_lowest_third_n:\n",
      "Number of unique values: 49\n",
      "\n",
      "math_lowest_third_n:\n",
      "Number of unique values: 45\n",
      "\n",
      "grad_rate_4yr:\n",
      "Number of unique values: 50\n",
      "\n",
      "grad_rate_6yr:\n",
      "Number of unique values: 41\n",
      "\n",
      "regents_english:\n",
      "Number of unique values: 56\n",
      "\n",
      "regents_algebra:\n",
      "Number of unique values: 37\n",
      "\n",
      "regents_living_env:\n",
      "Number of unique values: 39\n",
      "\n",
      "regents_global:\n",
      "Number of unique values: 44\n",
      "\n",
      "regents_us_history:\n",
      "Number of unique values: 44\n",
      "\n",
      "college_prep_index:\n",
      "Number of unique values: 54\n",
      "\n",
      "college_ready_4yr:\n",
      "Number of unique values: 54\n",
      "\n",
      "college_ready_6yr:\n",
      "Number of unique values: 48\n",
      "\n",
      "postsec_enroll_6mo:\n",
      "Number of unique values: 52\n",
      "\n",
      "postsec_enroll_18mo:\n",
      "Number of unique values: 45\n",
      "\n",
      "credits_yr1:\n",
      "Number of unique values: 56\n",
      "\n",
      "credits_yr2:\n",
      "Number of unique values: 55\n",
      "\n",
      "credits_yr3:\n",
      "Number of unique values: 54\n",
      "\n",
      "grad_rate_n:\n",
      "Number of unique values: 46\n",
      "\n",
      "regents_english_n:\n",
      "Number of unique values: 49\n",
      "\n",
      "college_ready_n:\n",
      "Number of unique values: 46\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 75\u001b[0m\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m missing_df\n\u001b[0;32m     74\u001b[0m \u001b[38;5;66;03m# Run analysis on final merged dataset\u001b[39;00m\n\u001b[1;32m---> 75\u001b[0m missing_data \u001b[38;5;241m=\u001b[39m analyze_data_quality(final_df, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFinal Merged Dataset\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[4], line 64\u001b[0m, in \u001b[0;36manalyze_data_quality\u001b[1;34m(df, dataset_name)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[38;5;28mprint\u001b[39m(df[col]\u001b[38;5;241m.\u001b[39mvalue_counts())\n\u001b[0;32m     63\u001b[0m \u001b[38;5;66;03m# Date columns analysis\u001b[39;00m\n\u001b[1;32m---> 64\u001b[0m date_cols \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mselect_dtypes(include\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdatetime64\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mperiod\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(date_cols) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     66\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m7. Date Range Analysis:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:5048\u001b[0m, in \u001b[0;36mDataFrame.select_dtypes\u001b[1;34m(self, include, exclude)\u001b[0m\n\u001b[0;32m   5045\u001b[0m             converted_dtypes\u001b[38;5;241m.\u001b[39mappend(infer_dtype_from_object(dtype))\n\u001b[0;32m   5046\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mfrozenset\u001b[39m(converted_dtypes)\n\u001b[1;32m-> 5048\u001b[0m include \u001b[38;5;241m=\u001b[39m check_int_infer_dtype(include)\n\u001b[0;32m   5049\u001b[0m exclude \u001b[38;5;241m=\u001b[39m check_int_infer_dtype(exclude)\n\u001b[0;32m   5051\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dtypes \u001b[38;5;129;01min\u001b[39;00m (include, exclude):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:5045\u001b[0m, in \u001b[0;36mDataFrame.select_dtypes.<locals>.check_int_infer_dtype\u001b[1;34m(dtypes)\u001b[0m\n\u001b[0;32m   5043\u001b[0m         converted_dtypes\u001b[38;5;241m.\u001b[39mextend([np\u001b[38;5;241m.\u001b[39mfloat64, np\u001b[38;5;241m.\u001b[39mfloat32])\n\u001b[0;32m   5044\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 5045\u001b[0m         converted_dtypes\u001b[38;5;241m.\u001b[39mappend(infer_dtype_from_object(dtype))\n\u001b[0;32m   5046\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mfrozenset\u001b[39m(converted_dtypes)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\dtypes\\common.py:1527\u001b[0m, in \u001b[0;36minfer_dtype_from_object\u001b[1;34m(dtype)\u001b[0m\n\u001b[0;32m   1525\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m DatetimeTZDtype\u001b[38;5;241m.\u001b[39mtype\n\u001b[0;32m   1526\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m dtype \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mperiod\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdatetime\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimedelta\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m   1530\u001b[0m     dtype \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m64\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Perform comprehensive data quality analysis\n",
    "def analyze_data_quality(df, dataset_name=\"Dataset\"):\n",
    "    \"\"\"\n",
    "    Analyze data quality including missing values, distributions, and potential issues.\n",
    "\"\"\"\n",
    "    print(f\"\\n{'='*20} {dataset_name} Analysis {'='*20}\")\n",
    "    \n",
    "    # Basic dataset information\n",
    "    print(\"\\n1. Basic Information:\")\n",
    "    print(f\"Number of rows: {len(df)}\")\n",
    "    print(f\"Number of columns: {len(df.columns)}\")\n",
    "    print(f\"Memory usage: {df.memory_usage().sum() / 1024**2:.2f} MB\")\n",
    "    \n",
    "    # Missing values analysis\n",
    "    print(\"\\n2. Missing Values Analysis:\")\n",
    "    missing = df.isnull().sum()\n",
    "    missing_pct = (df.isnull().sum() / len(df)) * 100\n",
    "    missing_df = pd.DataFrame({\n",
    "        'Missing Values': missing,\n",
    "        'Percentage': missing_pct\n",
    "    }).query('`Missing Values` > 0').sort_values('Percentage', ascending=False)\n",
    "    \n",
    "    if len(missing_df) > 0:\n",
    "        print(\"\\nColumns with missing values:\")\n",
    "        print(missing_df)\n",
    "    else:\n",
    "        print(\"No missing values found!\")\n",
    "    \n",
    "    # Data types\n",
    "    print(\"\\n3. Data Types:\")\n",
    "    print(df.dtypes.value_counts())\n",
    "    print(\"\\nDetailed dtypes:\")\n",
    "    print(df.dtypes)\n",
    "    \n",
    "    # Numerical columns analysis\n",
    "    numerical_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "    if len(numerical_cols) > 0:\n",
    "        print(\"\\n4. Numerical Columns Summary:\")\n",
    "        print(df[numerical_cols].describe())\n",
    "        \n",
    "        # Check for potential outliers\n",
    "        print(\"\\n5. Potential Outliers (values > 3 std devs from mean):\")\n",
    "        for col in numerical_cols:\n",
    "            mean = df[col].mean()\n",
    "            std = df[col].std()\n",
    "            outliers = df[col][(df[col] > mean + 3*std) | (df[col] < mean - 3*std)]\n",
    "            if len(outliers) > 0:\n",
    "                print(f\"\\n{col}:\")\n",
    "                print(f\"Number of outliers: {len(outliers)}\")\n",
    "                print(f\"Outlier values: {outliers.value_counts().head()}\")\n",
    "    \n",
    "    # Categorical columns analysis\n",
    "    categorical_cols = df.select_dtypes(include=['object', 'category']).columns\n",
    "    if len(categorical_cols) > 0:\n",
    "        print(\"\\n6. Categorical Columns Summary:\")\n",
    "        for col in categorical_cols:\n",
    "            unique_values = df[col].nunique()\n",
    "            print(f\"\\n{col}:\")\n",
    "            print(f\"Number of unique values: {unique_values}\")\n",
    "            if unique_values < 10:  # Only show value counts for columns with few unique values\n",
    "                print(df[col].value_counts())\n",
    "    \n",
    "    # Date columns analysis\n",
    "    date_cols = df.select_dtypes(include=['datetime64', 'period']).columns\n",
    "    if len(date_cols) > 0:\n",
    "        print(\"\\n7. Date Range Analysis:\")\n",
    "        for col in date_cols:\n",
    "            print(f\"\\n{col}:\")\n",
    "            print(f\"Min date: {df[col].min()}\")\n",
    "            print(f\"Max date: {df[col].max()}\")\n",
    "    \n",
    "    return missing_df\n",
    "\n",
    "# Run analysis on final merged dataset\n",
    "missing_data = analyze_data_quality(final_df, \"Final Merged Dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee9c96a5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'missing_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 24\u001b[0m\n\u001b[0;32m     21\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Create visualizations\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m plot_data_quality_visuals(final_df, missing_data)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'missing_data' is not defined"
     ]
    }
   ],
   "source": [
    "# Optional: Create visualizations for data quality metrics\n",
    "\n",
    "def plot_data_quality_visuals(df, missing_df):\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    # Missing values heatmap\n",
    "    plt.subplot(2, 1, 1)\n",
    "    sns.heatmap(df.isnull(), yticklabels=False, cbar=False, cmap='viridis')\n",
    "    plt.title('Missing Values Heatmap')\n",
    "    \n",
    "    # Distribution plots for key metrics\n",
    "    metrics = ['student_attendance_rate', 'achievement_score']  # Adjust based on your actual column names\n",
    "    plt.subplot(2, 1, 2)\n",
    "    for metric in metrics:\n",
    "        if metric in df.columns:\n",
    "            sns.kdeplot(data=df[metric].dropna(), label=metric)\n",
    "    plt.title('Distribution of Key Metrics')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Create visualizations\n",
    "plot_data_quality_visuals(final_df, missing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116e416d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
